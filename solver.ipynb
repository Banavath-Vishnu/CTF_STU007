{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import sys\n",
        "import csv\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import shap\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# UPDATE STUDENT ID. USE STU007 BECAUSE IT IS MINE (CASE-SENSITIVE)\n",
        "STUDENT_ID = input(\"Enter STUDENT ID MINE IS STU007 : \")\n",
        "BOOKS_PATH = \"/content/books.csv\"\n",
        "REVIEWS_PATH = \"/content/reviews.csv\"\n",
        "\n",
        "# --- SETUP ---\n",
        "# EnsurURING necessary NLTK data is available\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "def generate_student_hash(student_id):\n",
        "    \"\"\"Generates the 8-char uppercase SHA256 hash from Student ID.\"\"\"\n",
        "    hash_object = hashlib.sha256(student_id.encode())\n",
        "    return hash_object.hexdigest()[:8].upper()\n",
        "\n",
        "def solve_flag2(reviews_path, student_id, user_hash):\n",
        "    \"\"\"\n",
        "    FLAG 2: Locate the fake review containing the user hash.\n",
        "    Flag is simply FLAG2{USER_HASH}.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- SOLVING FLAG 2 ---\")\n",
        "    print(f\"Target Hash: {user_hash}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(reviews_path, engine='python', on_bad_lines='skip', quotechar='\"')\n",
        "        text_column = 'text'\n",
        "        if text_column in df.columns:\n",
        "            result = df[df[text_column].astype(str).str.contains(user_hash, case=False, na=False)]\n",
        "\n",
        "            if not result.empty:\n",
        "                print(f\"Success: Found {len(result)} review(s).\")\n",
        "                return f\"FLAG2 : {{{user_hash}}}\"\n",
        "            else:\n",
        "                return \"Error: Hash not found in dataset. Check Student ID.\"\n",
        "        else:\n",
        "            return f\"Error: Column '{text_column}' not found.\"\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: Dataset file not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def solve_flag1(books_path, reviews_path, target_hash):\n",
        "\n",
        "    print(f\"\\n--- SOLVING FLAG 1 ---\")\n",
        "    target_hash_lower = target_hash.lower()\n",
        "\n",
        "    try:\n",
        "        # 1. Filter Books\n",
        "        print(\"Loading books.csv...\")\n",
        "        df_books = pd.read_csv(books_path)\n",
        "        candidates = df_books[\n",
        "            (df_books['rating_number'] == 1234) &\n",
        "            (df_books['average_rating'] == 5.0)\n",
        "        ]\n",
        "\n",
        "        suspect_asins = set(candidates['parent_asin'].astype(str).str.strip().tolist())\n",
        "        print(f\"Found {len(suspect_asins)} \")\n",
        "\n",
        "        # 2. Search Reviews\n",
        "        print(\"Loading reviews.csv...\")\n",
        "        csv.field_size_limit(sys.maxsize)\n",
        "        df_reviews = pd.read_csv(reviews_path, engine='python', on_bad_lines='skip', quotechar='\"')\n",
        "\n",
        "        # Link via ASIN\n",
        "        df_reviews['asin'] = df_reviews['asin'].astype(str).str.strip()\n",
        "        relevant_reviews = df_reviews[df_reviews['asin'].isin(suspect_asins)]\n",
        "\n",
        "        found_asin = None\n",
        "\n",
        "        # Scan for hash\n",
        "        for index, row in relevant_reviews.iterrows():\n",
        "            review_text = str(row['text'])\n",
        "            if target_hash in review_text or target_hash_lower in review_text:\n",
        "                found_asin = row['asin']\n",
        "                print(f\"Match found in review for ASIN: {found_asin}\")\n",
        "                break\n",
        "\n",
        "        if not found_asin:\n",
        "            return \"Error: Hash not found in suspect reviews.\"\n",
        "\n",
        "        # 3. Retrieve Title & Hash\n",
        "        book_row = df_books[df_books['parent_asin'].astype(str).str.strip() == found_asin].iloc[0]\n",
        "        # Handle 'title' vs 'Title' column name case\n",
        "        official_title = str(book_row.get('title', book_row.get('Title', '')))\n",
        "\n",
        "        print(f\"Target Book Title: '{official_title}'\")\n",
        "\n",
        "        # Generate Flag\n",
        "        title_no_spaces = \"\".join(official_title.split())\n",
        "        seed_string = title_no_spaces[:8]\n",
        "        flag1 = hashlib.sha256(seed_string.encode()).hexdigest()\n",
        "\n",
        "        return flag1\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating Flag 1: {e}\"\n",
        "\n",
        "def solve_flag3(reviews_path, student_id):\n",
        "\n",
        "    print(f\"\\n--- SOLVING FLAG 3 ---\")\n",
        "\n",
        "    try:\n",
        "        print(\"Loading all reviews for global training...\")\n",
        "        df = pd.read_csv(reviews_path, engine='python', on_bad_lines='skip', quotechar='\"')\n",
        "        df['text'] = df['text'].astype(str).fillna(\"\")\n",
        "\n",
        "        # Label Data: 1=Suspicious(Short), 0=Genuine(Long/Detailed)\n",
        "        df['is_suspicious'] = df['text'].apply(lambda x: 1 if len(x) < 150 else 0)\n",
        "\n",
        "        # Train Model\n",
        "        print(\"Training Logistic Regression Model...\")\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "        X = vectorizer.fit_transform(df['text'])\n",
        "        y = df['is_suspicious']\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # SHAP Analysis on Genuine Reviews\n",
        "        print(\"Running SHAP analysis...\")\n",
        "        genuine_indices = np.where(y == 0)[0]\n",
        "        if len(genuine_indices) == 0: return \"Error: No genuine reviews.\"\n",
        "\n",
        "        # Sample 100 for speed\n",
        "        sample_indices = np.random.choice(genuine_indices, min(100, len(genuine_indices)), replace=False)\n",
        "        X_sample = X[sample_indices]\n",
        "\n",
        "        explainer = shap.LinearExplainer(model, X, feature_perturbation=\"interventional\")\n",
        "        shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "        # Find Top 3 \"Genuine\" words (Negative SHAP values)\n",
        "        mean_shap = np.mean(shap_values, axis=0)\n",
        "        feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "        top_indices = np.argsort(mean_shap)[:3]\n",
        "        top_words = feature_names[top_indices]\n",
        "\n",
        "        print(f\"Top 3 Genuine Words: {top_words}\")\n",
        "\n",
        "        # Generate Flag\n",
        "        numeric_id = re.search(r'\\d+', student_id).group()\n",
        "        combined_string = \"\".join(top_words) + numeric_id\n",
        "        full_hash = hashlib.sha256(combined_string.encode()).hexdigest()\n",
        "\n",
        "        return f\"FLAG3{{{full_hash[:10]}}}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating Flag 3: {e}\"\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Starting Solver for Student ID: {STUDENT_ID}\")\n",
        "\n",
        "    # 0. Prerequisite: Generate Hash\n",
        "    my_hash = generate_student_hash(STUDENT_ID)\n",
        "\n",
        "    # 1. Solve Flag 2 (Easiest)\n",
        "    flag2 = solve_flag2(REVIEWS_PATH, STUDENT_ID, my_hash)\n",
        "\n",
        "    # 2. Solve Flag 1 (Finding the Book)\n",
        "    flag1 = solve_flag1(BOOKS_PATH, REVIEWS_PATH, my_hash)\n",
        "\n",
        "    # 3. Solve Flag 3 (ML Analysis)\n",
        "    flag3 = solve_flag3(REVIEWS_PATH, STUDENT_ID)\n",
        "\n",
        "    # --- OUTPUT RESULTS ---\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"FINAL RESULTS\")\n",
        "    print(\"=\"*30)\n",
        "    print(f\"FLAG1 = {flag1}\")\n",
        "    print(f\"FLAG2 = {flag2}\")\n",
        "    print(f\"FLAG3 = {flag3}\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    # --- WRITE THE RESULTS IN FILES.TXT\n",
        "\n",
        "    try:\n",
        "      with open('flags.txt', 'w') as f:\n",
        "        f.write(\"FLAG1 : \" + flag1 + \"\\n\")\n",
        "        f.write(\" Flag2 : \" + flag2 + \"\\n\")\n",
        "        f.write(\"FLAG3 : \" + flag3 + \"\\n\")\n",
        "        print(\"Results written to flags.txt\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIMToTZYogFb",
        "outputId": "a0f08b37-a964-40cc-fa5f-b4b0be6dfaa6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter STUDENT ID MINE IS STU007 : STU007\n",
            "Starting Solver for Student ID: STU007\n",
            "\n",
            "--- SOLVING FLAG 2 ---\n",
            "Target Hash: 87ED580B\n",
            "Success: Found 1 review(s).\n",
            "\n",
            "--- SOLVING FLAG 1 ---\n",
            "Loading books.csv...\n",
            "Found 150 \n",
            "Loading reviews.csv...\n",
            "Match found in review for ASIN: 0006499333\n",
            "Target Book Title: 'Borrowed Time (Alistair MacLeanâ€™s UNACO)'\n",
            "\n",
            "--- SOLVING FLAG 3 ---\n",
            "Loading all reviews for global training...\n",
            "Training Logistic Regression Model...\n",
            "Running SHAP analysis...\n",
            "Top 3 Genuine Words: ['br' '34' 'like']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/shap/explainers/_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
            "  warnings.warn(wmsg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "FINAL RESULTS\n",
            "==============================\n",
            "FLAG1 = c88d22413095ddeec420b5e477c9ac87c29313a93dd4d0069c99ee907c209229\n",
            "FLAG2 = FLAG2 : {87ED580B}\n",
            "FLAG3 = FLAG3{e57aaf854d}\n",
            "==============================\n",
            "Results written to flags.txt\n"
          ]
        }
      ]
    }
  ]
}